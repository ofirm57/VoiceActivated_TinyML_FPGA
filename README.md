# Voice to FPGA ğŸ”Šâ¡ï¸ğŸ”Œ

This project is a voice-controlled embedded system using **TinyML** on the **DE10-Standard** board. It recognizes a spoken keyword (such as `"Go"`) and sends a command to the **FPGA fabric** to activate an LED, motor, or any logic-controlled component.

---

## ğŸ”§ Current Stage: Python-based Voice Capture & Preprocessing

At this point, the focus is on:
- Recording audio via microphone (`sounddevice`)
- Extracting features (such as energy / spectrogram)
- Preparing input format for TensorFlow Lite model inference
- Planning transition to embedded inference on ARM + FPGA

---

## ğŸ›  Tech Stack

- **Python 3.10**
- `numpy`, `scipy`, `sounddevice`, `tensorflow`
- Audio sampling rate: `16kHz`
- Recording duration: `3 seconds`
- Model format: `.tflite`

---

## ğŸ“ Project Structure

```bash
voice_to_fpga/
â”œâ”€â”€ main.py               # Records and plays voice
â”œâ”€â”€ preprocess.py         # Signal processing (WIP)
â”œâ”€â”€ model/                # Contains .tflite model
â”œâ”€â”€ utils/                # Helper functions
â”œâ”€â”€ README.md             # You are here
