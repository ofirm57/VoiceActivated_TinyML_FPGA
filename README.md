# Voice Activated - TinyML ğŸ”Šâ¡ï¸ğŸ”Œ

This project is a voice-controlled embedded system using TinyML on the DE10-Standard board.  
It recognizes spoken keywords (e.g., "up", "down", "left", "right", "stop") and sends a command to the FPGA to activate an LED, motor, or other hardware component.

---

## ğŸ“– About

Work-in-progress: full pipeline from keyword spotting to real-time FPGA control.  
The model was trained externally and deployed on the ARM processor for embedded inference.

---

## âœ… Whatâ€™s Done

- ğŸ“¥ Audio recording via microphone (`sounddevice`)  
- ğŸ§  MFCC feature extraction (`librosa`, `scipy`)  
- ğŸ§ª Training and evaluation of a CNN-based classification model  
- ğŸ§± Converted model to `.tflite` and tested locally  
- ğŸš€ Transferred code to run on ARM Cortex-A9 (embedded Linux)  
- ğŸ”— Sent commands from ARM to FPGA RTL logic via GPIO

---

## ğŸ”„ Current Stage

- Real-time end-to-end testing: microphone â†’ inference on ARM â†’ signal to FPGA  
- Inference runs with `tflite_runtime` on embedded Linux  
- SystemVerilog module receives and responds to prediction output

---

## ğŸ›  Tech Stack

- Python 3.10  
- Libraries: `numpy`, `scipy`, `librosa`, `sounddevice`, `tensorflow`, `tflite_runtime`  
- ARM Cortex-A9 on DE10-Standard (Linux)  
- Model Format: `.tflite`  
- Audio: 16kHz / 1â€“3 sec clips  
- RTL: SystemVerilog (Cyclone V SoC FPGA)

---

## ğŸ“ Project Structure

voice_to_fpga/
â”œâ”€â”€ main.py               # Entry point: coordinates recording, preprocessing, prediction
â”œâ”€â”€ recorder.py           # Handles microphone recording using sounddevice
â”œâ”€â”€ preprocessing.py      # Extracts MFCC features from audio
â”œâ”€â”€ predictor.py          # Loads and runs the TFLite model
â”œâ”€â”€ parctice_modle.py     # (Likely practice/training or debugging script)
â”œâ”€â”€ model/                # Contains the trained .tflite model
â”œâ”€â”€ rtl/                  # (Planned) SystemVerilog logic for FPGA response
â”œâ”€â”€ utils/                # Helper functions (e.g., file IO, logging)
â”œâ”€â”€ README.md             # You are here

---

## ğŸš€ Next Steps

- Add push-button override mechanism  
- Improve latency and timing precision  
- Add confidence/visual feedback (e.g., CLI plot)  
- Prepare for packaging and final deployment  
